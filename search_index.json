[["index.html", "Understanding Propensity Score Matching Chapter 1 Description 1.1 Main references", " Understanding Propensity Score Matching Ehsan Karim 2021-06-04 Chapter 1 Description Propensity score matching is widely used in analyzing observational datasets to reduce the impact of confounding due to observed covariates. This workshop will provide a basic overview of related causal inference concepts, explain propensity score matching analysis steps, illustrate propensity score matching diagnostics, and provide examples of when this method may be preferable to a regression. 1.1 Main references Propensity score matching steps Austin (2011a) Reporting guideline Karim et al. (2020) 1.1.1 Version history Materials were updated over time through various deliveries of the content: Understanding Propensity Score Matching: June 3, 2021, prepared as a Post Conference Workshop for 2021 Conference - CSEB. A Practical Introduction to Propensity Score Analysis using R: Sept 30, 2020, prepared for an invited webinar for Canadian Statistics Student Society, in collaboration with TI Methods. Introduction to Causal Inference: Propensity Score Analysis in Healthcare Data May 14, 2020, prepared for Population Data BC (in partnership with IC/ES). Also see further resources at the very end of the document. 1.1.2 Prerequisites The prerequisites are knowledge of multiple regression analysis and basic probability. Software demonstrations and codes will be provided in R, although proficiency in R is not required for understanding the concepts. 1.1.3 Comments For any comments regarding this document, reach out to me. "],["terms.html", "Chapter 2 Defining Parameter 2.1 Potential outcome 2.2 Parameters of interest", " Chapter 2 Defining Parameter We are particularly interested about estimating the parameter treatment effect estimate. For that, let us define the notations first. 2.1 Potential outcome \\(A\\): Exposure status \\(1\\) = takes Rosuvastatin \\(0\\) = does not take rosuvastatin \\(Y\\): Outcome: Total cholesterol levels \\(Y(A=1)\\) = potential outcome when exposed \\(Y(A=0)\\) = potential outcome when not exposed \\(L\\): Risk factor (or later Confounder when randomization not present): Age 2.2 Parameters of interest When assessing the effect of an exposure on an outcome, we are interested about the following estimands treatment effect for an individual (TE) average treatment effect (ATE) average treatment effect on the treated (ATT) 2.2.1 TE John takes Rosuvastatin \\((A=1)\\) and his total cholesterol level is = \\(Y(A=1)\\) = \\(195\\) mg/dL (milligrams per deciliter) after 3 months John does not take Rosuvastatin \\((A=0)\\) and his total cholesterol level is = \\(Y(A=0)\\) = \\(245\\) mg/dL after 3 months Effect of Rosuvastatin on John is = \\(TE = Y(A=1) - Y(A=0) = 195 - 245 = - 50\\) TE is not estimable as we generally cant observe outcomes under both treatment conditions. 2.2.2 ATE Person &lt;- c(&quot;John&quot;,&quot;Jim&quot;,&quot;Jake&quot;,&quot;Cody&quot;,&quot;Luke&quot;) Y1 &lt;- c( 195, 100, 210, 155, 165) Y0 &lt;- c(245, 160, 270, 210, 230) PotentialOutcomes &lt;- data.frame(Person, Y1, Y0, TE = Y1-Y0) mean.values &lt;- c(NA, mean(PotentialOutcomes$Y1), mean(PotentialOutcomes$Y0), mean(PotentialOutcomes$TE)) PotentialOutcomes &lt;- rbind(PotentialOutcomes, mean.values) kable(PotentialOutcomes, booktabs = TRUE, col.names = c(&quot;Person&quot;, &quot;Y(1)&quot;, &quot;Y(0)&quot;, &quot;TE&quot;)) %&gt;% row_spec(6, bold = T, color = &quot;white&quot;, background = &quot;#D7261E&quot;) Person Y(1) Y(0) TE John 195 245 -50 Jim 100 160 -60 Jake 210 270 -60 Cody 155 210 -55 Luke 165 230 -65 165 223 -58 \\(ATE = E[Y(A=1)-Y(A=0)]\\) mean(PotentialOutcomes$Y1 - PotentialOutcomes$Y0) ## [1] -58 2.2.3 Interpretation of ATE This is a treatment effect (on an average) of the following hypothetical situation having the entire population as treated, vs. having the entire population as untreated. Entire population is the reference goup here. 2.2.4 Identifiability Assumptions If we can compute a causal quantity, such as \\(ATE = E[Y(A=1)-Y(A=0)]\\) using a statistical quantity, such as mean(PotentialOutcomes$Y1 - PotentialOutcomes$Y0), we say that the causal quantity is identifiable. Exchangeability \\(Y(1), Y(0) \\perp A\\) Treatment assignment is independent of the potential outcome Positivity \\(0 &lt; P(A=1) &lt; 1\\) Subjects are eligible to receive both treatment Consistency \\(Y = Y(a) \\forall A=a\\) No multiple version of the treatment No interference Treated one patient will not impact outcome for others Extending these assumptions when confounders exist: Conditional Exchangeability \\(Y(1), Y(0) \\perp A | L\\) Treatment assignment is independent of the potential outcome, given L Positivity \\(0 &lt; P(A=1 | L) &lt; 1\\) Subjects are eligible to receive both treatment, given L 2.2.5 ATT Assume that the following are the confounders that impact the relationship between rosuvastatin and cholesterol levels race sex age We have 5 Rosuvastatin-treated subjects who are all white, male, 50 years of age We recruited additional 5 subjects (same characteristics) to non-rosuvastatin group. Treated group: Person &lt;- c(&quot;John&quot;,&quot;Jim&quot;,&quot;Jake&quot;,&quot;Cody&quot;,&quot;Luke&quot;) Y1 &lt;- c( 195, 100, 210, 155, 165) Y0 &lt;- rep(NA, length(Y1)) Treated &lt;- data.frame(Person, Y1, Y0, TE = Y1-Y0) Treated[6,2] &lt;- mean(Treated$Y1) kable(Treated, booktabs = TRUE, col.names = c(&quot;Person&quot;, &quot;Y(1)&quot;, &quot;Y(0)&quot;, &quot;TE&quot;))%&gt;% row_spec(6, bold = T, color = &quot;white&quot;, background = &quot;#D7261E&quot;) Person Y(1) Y(0) TE John 195 Jim 100 Jake 210 Cody 155 Luke 165 165 Untreated group: New folks with characteristics similar to the treated group. Person &lt;- c( &quot;Jack&quot;, &quot;Dustin&quot;, &quot;Cole&quot;, &quot;Lucas&quot;, &quot;Dylan&quot;) Y0 &lt;- c( 245, 160, 270, 210, 165) Y1 &lt;- rep(NA, length(Y0)) Untreated &lt;- data.frame(Person, Y1, Y0, TE = Y1-Y0) Untreated[6,3] &lt;- mean(Untreated$Y0) kable(Untreated, booktabs = TRUE, col.names = c(&quot;Person&quot;, &quot;Y(1)&quot;, &quot;Y(0)&quot;, &quot;TE&quot;))%&gt;% row_spec(6, bold = T, color = &quot;white&quot;, background = &quot;#D7261E&quot;) Person Y(1) Y(0) TE Jack 245 Dustin 160 Cole 270 Lucas 210 Dylan 165 210 \\(ATT = E[Y(A=1)-Y(A=0) | A = 1]\\) mean(Treated$Y1) - mean(Untreated$Y0) ## [1] -45 2.2.6 Interpretation of ATT This is a treatment effect (on an average) of the treated population (reference group), vs. untreated population, but have similar characteristics to the reference group/treated population. It is also possible to change the reference population to untreated population. Then it is called Average Treatment Effect for the Untreated (ATU). 2.2.7 ATT vs. ATE In a RCT (enough n), the ATT &amp; ATE are equivalent In an observational study the ATT and ATE are not necessarily the same. "],["balance.html", "Chapter 3 Balance and Overlap 3.1 Balance 3.2 Adjustment 3.3 Lack of overlap", " Chapter 3 Balance and Overlap 3.1 Balance Balance in RCT: In absence of randomization: 3.1.1 Measures of Balance 3.1.1.1 SMD Austin (2011b) For continuous confounders: \\(SDM_{continuous} = \\frac{\\bar{L}_{Rosuvastatin} - \\bar{L}_{No Rosuvastatin}}{\\sqrt{\\frac{s^2_{Rosuvastatin} + s^2_{No Rosuvastatin}}{2}}}\\) For binary confounders: \\(SDM_{binary} = \\frac{\\hat{p}_{Rosuvastatin} - \\hat{p}_{No Rosuvastatin}}{\\sqrt{\\frac{ \\hat{p}_{Rosuvastatin} \\times (1 - \\hat{p}_{Rosuvastatin}) + \\hat{p}_{No Rosuvastatin} \\times (1 - \\hat{p}_{No Rosuvastatin}) }{2}}}\\) Generally, \\(0.1\\) is used as a cut-point. But some suggest more liberal cut-points. More on that later. 3.1.1.2 Variance ratio Variances of baseline characteristics between comparator groups under consideration. Suggested cut-point rages are (0.5 to 2). More liberal cut-points are also used in the literature. More on this later. 3.2 Adjustment 3.2.1 Why adjust? In absence of randomization, treatment effect estimate ATE = \\(E[Y|A=1] - E[Y|A=0]\\) includes Treatment effect Systematic differences in 2 groups (confounding) Doctors may prescribe tx more to frail and older age patients. In here, \\(L\\) = age is a confounder. In absence of randomization, if age is a known confounder, conditioning can solve the problem: Causal effect for young (\\(&lt;50\\)) \\(E[Y|A=1, L =\\) younger age\\(]\\) - \\(E[Y|A=0, L =\\) younger age\\(]\\) Causal effect for old (\\(\\ge 50\\)) \\(E[Y|A=1, L =\\) older age\\(]\\) - \\(E[Y|A=0, L =\\) older age\\(]\\) Conditional exchangeability; only works if \\(L\\) is measured. 3.2.2 Adjustment Methods Adjustment of imbalance could mean exact matching stratification When L includes a large number of covariates, matching method would result in a small sample size. Regression is also a popular adjustment method. 3.3 Lack of overlap Lack of complete overlap happens if there is a baseline covariate space where there are exposed patients, but no control or vice versa. Region of no overlap is an inherent limitation of the data. Regression adjustment usually do not offer any solution to this. Consequently, inference is not generalizable beyond the region of overlap. "],["ps.html", "Chapter 4 Propensity score 4.1 Motivating problem 4.2 Defining Propensity score 4.3 PS Matching Steps", " Chapter 4 Propensity score 4.1 Motivating problem \\(Y\\) : Outcome Cholesterol levels (high vs. low) \\(A\\) : Exposure Diabetes \\(L\\) : Known Confounders gender, age, race, education, married, BMI Search literature for the confounder variables, and look for those variables in the data source (NHANES 2017-2018). Data recourses: All of the data files used in this workshop are available in the GitHub repo. load(file=&quot;data/NHANES17.RData&quot;) require(dplyr) analytic &lt;- dplyr::select(analytic, cholesterol, # outcome gender, age, race, education, married, bmi, # confounders diabetes) # exposure analytic$cholesterol &lt;- ifelse(analytic$cholesterol &gt; 240, 1, 0) analytic$diabetes &lt;- ifelse(analytic$diabetes == &quot;Yes&quot;, 1, 0) require(summarytools) dfSummary(analytic) ## Data Frame Summary ## analytic ## Dimensions: 1562 x 8 ## Duplicates: 2 ## ## ----------------------------------------------------------------------------------------------------------------------------------------------------------------- ## No Variable Label Stats / Values Freqs (% of Valid) Graph Valid Missing ## ---- --------------------- --------------------------- -------------------------- --------------------- ------------------------------------ ---------- --------- ## 1 cholesterol Min : 0 0 : 1391 (89.1%) IIIIIIIIIIIIIIIII 1562 0 ## [numeric] Mean : 0.1 1 : 171 (10.9%) II (100.0%) (0.0%) ## Max : 1 ## ## 2 gender 1. Female 603 (38.6%) IIIIIII 1562 0 ## [character] 2. Male 959 (61.4%) IIIIIIIIIIII (100.0%) (0.0%) ## ## 3 age Age in years at screening Mean (sd) : 53.2 (17.2) 61 distinct values : : : 1562 0 ## [labelled, integer] min &lt; med &lt; max: . : . . : : : : : (100.0%) (0.0%) ## 20 &lt; 55 &lt; 80 : : : : : : : : : : ## IQR (CV) : 29 (0.3) : : : : : : : : : : ## : : : : : : : : : : ## ## 4 race 1. Black 324 (20.7%) IIII 1562 0 ## [character] 2. Hispanic 284 (18.2%) III (100.0%) (0.0%) ## 3. Other 228 (14.6%) II ## 4. White 726 (46.5%) IIIIIIIII ## ## 5 education 1. College 806 (51.6%) IIIIIIIIII 1562 0 ## [character] 2. High.School 658 (42.1%) IIIIIIII (100.0%) (0.0%) ## 3. School 98 ( 6.3%) I ## ## 6 married 1. Married 921 (59.0%) IIIIIIIIIII 1562 0 ## [character] 2. Never.married 228 (14.6%) II (100.0%) (0.0%) ## 3. Previously.married 413 (26.4%) IIIII ## ## 7 bmi Body Mass Index (kg/m2) Mean (sd) : 30 (7.3) 314 distinct values : 1562 0 ## [labelled, numeric] min &lt; med &lt; max: : . (100.0%) (0.0%) ## 14.8 &lt; 28.9 &lt; 64.2 : : : ## IQR (CV) : 8.8 (0.2) : : : : ## . : : : : : . ## ## 8 diabetes Min : 0 0 : 1232 (78.9%) IIIIIIIIIIIIIII 1562 0 ## [numeric] Mean : 0.2 1 : 330 (21.1%) IIII (100.0%) (0.0%) ## Max : 1 ## ----------------------------------------------------------------------------------------------------------------------------------------------------------------- 4.2 Defining Propensity score Conditional Probability of getting treatment, given the observed covariates Prob(treatment: \\(A = 1\\) | baseline or pre-treatment covariates: \\(L\\)) Prob(\\(A = 1\\): Has diabetes | \\(L\\): gender, age, race, education, married, bmi) PS = \\(Prob(A=1|L)\\) Condensing multiple variables (in L) into one summary variable (PS). Essentially a dimension reduction exercise! 4.2.1 Theoretical result Rosenbaum and Rubin (1983) showed: For potential outcomes \\(Y(1), Y(0)\\), if you have sufficient observed covariate list \\(L\\) to reduce confounding (`strong ignoribility): i.e., if \\((Y(1), Y(0)) \\perp A | L\\) Note that is this NOT \\(Y \\perp A | L\\) then \\((Y(1), Y(0)) \\perp A | PS\\) and \\(A \\perp L | PS\\) 4.2.2 Assumptions Conditional Exchangeability \\(Y(1), Y(0) \\perp A | L\\) Treatment assignment is independent of the potential outcome, given L Positivity \\(0 &lt; P(A=1 | L) &lt; 1\\) Subjects are eligible to receive both treatment, given L Consistency \\(Y = Y(a) \\forall A=a\\) No multiple version of the treatment 4.2.3 Ways to use PS Many ways to use propensity scores (PS) in the analysis PS matching [our focus today] PS weighting PS stratification PS used as a covariate 4.3 PS Matching Steps Propensity score matching has 4 steps (Austin 2011a) Step 1 exposure modelling: \\(PS = Prob(A=1|L)\\) Step 2 Match by \\(PS\\) Step 3 Assess balance and overlap (\\(PS\\) and \\(L\\)) Step 4 outcome modelling: \\(Prob(Y=1|A=1)\\) "],["s1.html", "Chapter 5 Step 1: Exposure modelling 5.1 Model specification 5.2 Variables to adjust 5.3 Model selection 5.4 Alternative modelling strategies 5.5 PS estimation 5.6 General FAQ", " Chapter 5 Step 1: Exposure modelling 5.1 Model specification Specify the propensity score model to estimate propensity scores, and fit the model: \\(A \\sim L\\) baselinevars &lt;- c(&quot;gender&quot;, &quot;age&quot;, &quot;race&quot;, &quot;education&quot;, &quot;married&quot;, &quot;bmi&quot;) ps.formula &lt;- as.formula(paste(&quot;diabetes&quot;, &quot;~&quot;, paste(baselinevars, collapse = &quot;+&quot;))) ps.formula ## diabetes ~ gender + age + race + education + married + bmi # fit logistic regression to estimate propensity scores PS.fit &lt;- glm(ps.formula,family=&quot;binomial&quot;, data=analytic) require(jtools) summ(PS.fit) Observations 1562 Dependent variable diabetes Type Generalized linear model Family binomial Link logit ²(10) 282.89 Pseudo-R² (Cragg-Uhler) 0.26 Pseudo-R² (McFadden) 0.18 AIC 1349.94 BIC 1408.83 Est. S.E. z val. p (Intercept) -8.38 0.58 -14.49 0.00 genderMale 0.34 0.15 2.26 0.02 age 0.06 0.01 11.26 0.00 raceHispanic 0.15 0.23 0.64 0.52 raceOther 0.76 0.23 3.25 0.00 raceWhite -0.23 0.18 -1.23 0.22 educationHigh.School 0.14 0.15 0.95 0.34 educationSchool 0.52 0.27 1.92 0.05 marriedNever.married -0.04 0.25 -0.16 0.88 marriedPreviously.married -0.02 0.16 -0.15 0.88 bmi 0.10 0.01 10.14 0.00 Standard errors: MLE Coef of PS model fit is not of concern Model can be rich: to the extent that prediction is better But look for multi-collinearity issues SE too high? 5.2 Variables to adjust Brookhart et al. (2006) Observed covariates are used to fix design Which covariates should be selected: known to be a confounder (causes of \\(Y\\) and \\(A\\)) known to be a cause of the outcome (risk factors of \\(Y\\)) avoid known instruments or noise variables: SE suffers mediating factors should be avoided (total effect = goal) Try drawing causal diagram to determine which variables to include 5.3 Model selection Usually done for the variables that are not known as a confounder in the literature, or based on subject area knowledge. Stepwise (p-value or criterion based) not recommended depending on sample size, different values can get selected may select variables highly associated with \\(A\\) Dont look at the outcome (\\(Y\\)) in your data to select covariates There are debate about this (ideal vs. pragmatism) see Karim, Pang, and Platt (2018) for an example. 5.4 Alternative modelling strategies Other machine learning alternatives are possible to use instead of logistic regression. tree based methods have better ability to detect non-linearity / non-additivity (model-specification aspect) shrinkage methods - lasso / elastic net may better deal with multi-collinearity ensemble learners / super learners were successfully used shallow/deep learning! 5.5 PS estimation PS is unknown, and needs to be estimated from the fitted exposure model: # extract estimated propensity scores from the fit analytic$PS &lt;- predict(PS.fit, newdata = analytic, type=&quot;response&quot;) require(cobalt) bal.plot(analytic, var.name = &quot;PS&quot;, treat = &quot;diabetes&quot;, which = &quot;both&quot;, data = analytic) Dont loose sight that better balance is the ultimate goal for propensity score Prediction of \\(A\\) is just a means to that end (as true PS is unknown) May attract variables highly associated with \\(A\\) 5.6 General FAQ How many variables in PS model are too many? Depends on the sample size Again look at the stability: the exposure model coef SEs What other model specifications are possible? Common terms to add # Interactions ps.formula2 &lt;- as.formula(paste(&quot;diabetes&quot;, &quot;~&quot;, paste(baselinevars, collapse = &quot;+&quot;), &quot;+ education:bmi + gender:age&quot;)) ps.formula2 ## diabetes ~ gender + age + race + education + married + bmi + ## education:bmi + gender:age # polynomials ps.formula3 &lt;- as.formula(paste(&quot;diabetes&quot;, &quot;~&quot;, paste(baselinevars, collapse = &quot;+&quot;), &quot;+ age^2 + + age^3&quot;)) ps.formula3 ## diabetes ~ gender + age + race + education + married + bmi + ## age^2 + +age^3 How to incorporate mediator variable in the PS analysis? One example of a mediator variable in out analysis could be physical exercise. In the current framework, we do not include mediator variables as we are primarily interested about total effect, not any decomposition. "],["s2.html", "Chapter 6 Step 2: Propensity score Matching 6.1 Matching method NN 6.2 Initial fit 6.3 Fine tuning: add caliper 6.4 Matches 6.5 Other matching algorithms", " Chapter 6 Step 2: Propensity score Matching 6.1 Matching method NN Match using estimates propensity scores nearest-neighbor (NN) matching without replacement with caliper = .2*SD of logit of propensity score with 1:1 ratio (pair-matching) 6.2 Initial fit 1:1 NN Match using estimates propensity scores set.seed(123) require(MatchIt) match.obj &lt;- matchit(ps.formula, data = analytic, distance = &#39;logit&#39;, method = &quot;nearest&quot;, replace=FALSE, ratio = 1) analytic$PS &lt;- match.obj$distance summary(match.obj$distance) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.003916 0.068128 0.169946 0.211268 0.312987 0.925132 match.obj ## A matchit object ## - method: 1:1 nearest neighbor matching without replacement ## - distance: Propensity score ## - estimated with logistic regression ## - number of obs.: 1562 (original), 660 (matched) ## - target estimand: ATT ## - covariates: gender, age, race, education, married, bmi 6.3 Fine tuning: add caliper 2 SD of logit of the propensity score is suggested as a caliper. logitPS &lt;- -log(1/analytic$PS - 1) # logit of the propensity score .2*sd(logitPS) # suggested in the literature ## [1] 0.2606266 # choosing too strict PS has unintended consequences set.seed(123) require(MatchIt) match.obj &lt;- matchit(ps.formula, data = analytic, distance = &#39;logit&#39;, method = &quot;nearest&quot;, replace=FALSE, caliper = .2*sd(logitPS), ratio = 1) analytic$PS &lt;- match.obj$distance summary(match.obj$distance) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.003916 0.068128 0.169946 0.211268 0.312987 0.925132 match.obj ## A matchit object ## - method: 1:1 nearest neighbor matching without replacement ## - distance: Propensity score [caliper] ## - estimated with logistic regression ## - caliper: &lt;distance&gt; (0.045) ## - number of obs.: 1562 (original), 632 (matched) ## - target estimand: ATT ## - covariates: gender, age, race, education, married, bmi 6.4 Matches Taking a closer look at the matches # Ref: https://lists.gking.harvard.edu/pipermail/matchit/2013-October/000559.html matches &lt;- as.data.frame(match.obj$match.matrix) colnames(matches)&lt;-c(&quot;matched_unit&quot;) matches$matched_unit&lt;-as.numeric( as.character(matches$matched_unit)) matches$treated_unit&lt;-as.numeric(rownames(matches)) matches.only&lt;-matches[!is.na(matches$matched_unit),] head(matches.only) ## matched_unit treated_unit ## 40 8496 40 ## 56 3139 56 ## 65 4192 65 ## 66 94 66 ## 86 2212 86 ## 110 7154 110 6.5 Other matching algorithms More NN ratio is usually better. But creates issue when calculating variances (but can be easily handled). Other possibilities Optimal genetic matching CEM variable ratio NN "],["s3.html", "Chapter 7 Step 3: Balance and overlap 7.1 Assessment of Balance by SMD 7.2 SMD vs. P-values 7.3 Vizualization for Overlap 7.4 Variance ratio 7.5 Close inspection of boundaries 7.6 Unsatirfactory balance", " Chapter 7 Step 3: Balance and overlap Balance is more important than prediction! Criteria to assess success of step 2: PS estimation better balance better overlap [no extrapolation!] PS = 0 or PS = 1 needs close inspection 7.1 Assessment of Balance by SMD balance = similarity of the covariate distributions Full data: tab1e &lt;- CreateTableOne(vars = baselinevars, data = analytic, strata = &quot;diabetes&quot;, includeNA = TRUE, test = TRUE, smd = TRUE) print(tab1e, showAllLevels = FALSE, smd = TRUE, test = TRUE) ## Stratified by diabetes ## 0 1 p test SMD ## n 1232 330 ## gender = Male (%) 738 (59.9) 221 (67.0) 0.023 0.147 ## age (mean (SD)) 50.54 (17.23) 63.04 (12.87) &lt;0.001 0.822 ## race (%) 0.110 0.151 ## Black 253 (20.5) 71 (21.5) ## Hispanic 220 (17.9) 64 (19.4) ## Other 169 (13.7) 59 (17.9) ## White 590 (47.9) 136 (41.2) ## education (%) 0.005 0.186 ## College 649 (52.7) 157 (47.6) ## High.School 518 (42.0) 140 (42.4) ## School 65 ( 5.3) 33 (10.0) ## married (%) &lt;0.001 0.282 ## Married 727 (59.0) 194 (58.8) ## Never.married 201 (16.3) 27 ( 8.2) ## Previously.married 304 (24.7) 109 (33.0) ## bmi (mean (SD)) 29.14 (7.03) 33.01 (7.65) &lt;0.001 0.526 Matched data: matched.data &lt;- match.data(match.obj) tab1m &lt;- CreateTableOne(vars = baselinevars, strata = &quot;diabetes&quot;, data = matched.data, includeNA = TRUE, test = TRUE, smd = TRUE) Compare the similarity of baseline characteristics between treated and untreated subjects in a the propensity score-matched sample. In this case, we will compare SMD &lt; 0.1 or not. In some literature, other generous values (0.25) are proposed. (Austin 2011b) print(tab1m, showAllLevels = FALSE, smd = TRUE, test = FALSE) ## Stratified by diabetes ## 0 1 SMD ## n 316 316 ## gender = Male (%) 218 (69.0) 212 (67.1) 0.041 ## age (mean (SD)) 63.03 (13.48) 62.67 (12.87) 0.027 ## race (%) 0.105 ## Black 79 (25.0) 68 (21.5) ## Hispanic 58 (18.4) 61 (19.3) ## Other 44 (13.9) 53 (16.8) ## White 135 (42.7) 134 (42.4) ## education (%) 0.007 ## College 153 (48.4) 152 (48.1) ## High.School 133 (42.1) 134 (42.4) ## School 30 ( 9.5) 30 ( 9.5) ## married (%) 0.099 ## Married 183 (57.9) 186 (58.9) ## Never.married 20 ( 6.3) 27 ( 8.5) ## Previously.married 113 (35.8) 103 (32.6) ## bmi (mean (SD)) 32.38 (7.62) 32.63 (7.20) 0.035 7.2 SMD vs. P-values Possible to get p-values to check balance: but strongly discouraged P-value based balance assessment can be influenced by sample size print(tab1m, showAllLevels = FALSE, smd = FALSE, test = TRUE) ## Stratified by diabetes ## 0 1 p test ## n 316 316 ## gender = Male (%) 218 (69.0) 212 (67.1) 0.670 ## age (mean (SD)) 63.03 (13.48) 62.67 (12.87) 0.733 ## race (%) 0.629 ## Black 79 (25.0) 68 (21.5) ## Hispanic 58 (18.4) 61 (19.3) ## Other 44 (13.9) 53 (16.8) ## White 135 (42.7) 134 (42.4) ## education (%) 0.996 ## College 153 (48.4) 152 (48.1) ## High.School 133 (42.1) 134 (42.4) ## School 30 ( 9.5) 30 ( 9.5) ## married (%) 0.465 ## Married 183 (57.9) 186 (58.9) ## Never.married 20 ( 6.3) 27 ( 8.5) ## Previously.married 113 (35.8) 103 (32.6) ## bmi (mean (SD)) 32.38 (7.62) 32.63 (7.20) 0.662 Assessment of balance in the matched data smd.res &lt;- ExtractSmd(tab1m) t(round(smd.res,2)) ## gender age race education married bmi ## 1 vs 2 0.04 0.03 0.11 0.01 0.1 0.03 COVID example from Gautret et al. (2020) p-value vs. SMD 7.3 Vizualization for Overlap boxplot(PS ~ diabetes, data = analytic, lwd = 2, ylab = &#39;PS&#39;) stripchart(PS ~ diabetes, vertical = TRUE, data = analytic, method = &quot;jitter&quot;, add = TRUE, pch = 20, col = &#39;blue&#39;) plot(match.obj, type = &quot;jitter&quot;) ## [1] &quot;To identify the units, use first mouse button; to stop, use second.&quot; ## integer(0) Vizualization for assessing overlap issues plot(match.obj, type = &quot;hist&quot;) 7.4 Variance ratio Variance ratios \\(\\sim\\) 1 means: equal variances in groups group balance could vary from 1/2 to 2 other cut-points are suggested as well (0.8 to 1.2) See Stuart (2010) and Austin (2009) require(cobalt) baltab.res &lt;- bal.tab(x = match.obj, data = analytic, treat = analytic$diabetes, disp.v.ratio = TRUE) baltab.res ## Call ## matchit(formula = ps.formula, data = analytic, method = &quot;nearest&quot;, ## distance = &quot;logit&quot;, replace = FALSE, caliper = 0.2 * sd(logitPS), ## ratio = 1) ## ## Balance Measures ## Type Diff.Adj V.Ratio.Adj ## distance Distance 0.0276 1.0992 ## gender_Male Binary -0.0190 ## age Contin. -0.0278 0.9114 ## race_Black Binary -0.0348 ## race_Hispanic Binary 0.0095 ## race_Other Binary 0.0285 ## race_White Binary -0.0032 ## education_College Binary -0.0032 ## education_High.School Binary 0.0032 ## education_School Binary 0.0000 ## married_Married Binary 0.0095 ## married_Never.married Binary 0.0222 ## married_Previously.married Binary -0.0316 ## bmi Contin. 0.0338 0.8928 ## ## Sample sizes ## Control Treated ## All 1232 330 ## Matched 316 316 ## Unmatched 916 14 7.5 Close inspection of boundaries boxplot(PS ~ diabetes, data = matched.data, lwd = 2, ylab = &#39;PS&#39;, ylim=c(0,1)) stripchart(PS ~ diabetes, vertical = TRUE, data = matched.data, method = &quot;jitter&quot;, add = TRUE, pch = 20, col = &#39;blue&#39;) abline(h=c(0+0.05,1-0.05), col = &quot;red&quot;, lty = 2) Sensitivity analysis should be done with trimming. Have consequences in interpretation target populstion may be unclear 7.6 Unsatirfactory balance Best strategy is to go back to step 2, and make changes in the PS model specification "],["s4.html", "Chapter 8 Step 4: Outcome modelling 8.1 Crude outcome model 8.2 Double-adjustment 8.3 Adjusted outcome model 8.4 Other cosiderations for outcome model 8.5 Estimate obtained", " Chapter 8 Step 4: Outcome modelling Some flexibility in choosing outcome model considered independent of exposure modelling some propose double robust approach adjusting imbalanced covariates only? double-adjustment may address residual confounding (Nguyen et al. 2017) 8.1 Crude outcome model Estimate the effect of treatment on outcomes using propensity score-matched sample fit3 &lt;- glm(cholesterol~diabetes, family=binomial, data = matched.data) publish(fit3) ## Variable Units OddsRatio CI.95 p-value ## diabetes 0.90 [0.54;1.50] 0.6984 8.2 Double-adjustment Estimate the effect of treatment on outcomes using propensity score-matched sample, and adjust for imbalanced covariate fit3r &lt;- glm(cholesterol~diabetes + race, family=binomial, data = matched.data) publish(fit3r) ## Variable Units OddsRatio CI.95 p-value ## diabetes 0.89 [0.54;1.49] 0.6657 ## race Black Ref ## Hispanic 0.96 [0.46;2.02] 0.9165 ## Other 1.32 [0.63;2.78] 0.4581 ## White 0.58 [0.30;1.13] 0.1095 8.3 Adjusted outcome model Adjust for all covariates, again! (suggested) out.formula &lt;- as.formula(paste(&quot;cholesterol&quot;, &quot;~ diabetes +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) out.formula ## cholesterol ~ diabetes + gender + age + race + education + married + ## bmi fit3b &lt;- glm(out.formula, family=binomial, data = matched.data) publish(fit3b) ## Variable Units OddsRatio CI.95 p-value ## diabetes 0.86 [0.51;1.46] 0.5794126 ## gender Female Ref ## Male 0.38 [0.21;0.69] 0.0012767 ## age 0.95 [0.93;0.97] &lt; 1e-04 ## race Black Ref ## Hispanic 0.72 [0.31;1.65] 0.4346787 ## Other 0.77 [0.34;1.73] 0.5224157 ## White 0.51 [0.25;1.04] 0.0649791 ## education College Ref ## High.School 0.70 [0.39;1.24] 0.2215142 ## School 0.93 [0.35;2.43] 0.8791455 ## married Married Ref ## Never.married 0.48 [0.15;1.54] 0.2173180 ## Previously.married 0.84 [0.45;1.57] 0.5900732 ## bmi 0.93 [0.89;0.97] 0.0005547 The above analysis do not take matched pair into consideration while regressing. 8.4 Other cosiderations for outcome model Literature proposes different strategies: do not control for pairs / clusters use glm as is control for pairs / clusters use cluster option (preferred) use GEE or use conditional logistic Here is an example using cluster option: require(jtools) summ(fit3b, rubust = &quot;HC0&quot;, confint = TRUE, digists = 3, cluster = &quot;subclass&quot;, model.info = FALSE, model.fit = FALSE, exp = TRUE) exp(Est.) 2.5% 97.5% z val. p (Intercept) 100.02 8.74 1144.55 3.70 0.00 diabetes 0.86 0.51 1.46 -0.55 0.58 genderMale 0.38 0.21 0.69 -3.22 0.00 age 0.95 0.93 0.97 -4.47 0.00 raceHispanic 0.72 0.31 1.65 -0.78 0.43 raceOther 0.77 0.34 1.73 -0.64 0.52 raceWhite 0.51 0.25 1.04 -1.85 0.06 educationHigh.School 0.70 0.39 1.24 -1.22 0.22 educationSchool 0.93 0.35 2.43 -0.15 0.88 marriedNever.married 0.48 0.15 1.54 -1.23 0.22 marriedPreviously.married 0.84 0.45 1.57 -0.54 0.59 bmi 0.93 0.89 0.97 -3.45 0.00 Standard errors: MLE Bootstrap for matched pairfor WOR (Austin and Small 2014) may not be appropriate for WR 8.5 Estimate obtained The example compared diabetic (a treated group; target) vs Not diabetic (untreated). Thc corresponding treatment effect estimate is known as Average Treatment Effects on the Treated (ATT) Other estimates from PS analysis (e.g., PS weighting) are possible that compared the whole population what if everyone treated vs. what if nobody was treated (ATE) "],["compare.html", "Chapter 9 PS vs. Regression 9.1 Data Simulation 9.2 Treatment effect from counterfactuals 9.3 Treatment effect from Regression 9.4 Treatment effect from PS 9.5 Non-linear Model", " Chapter 9 PS vs. Regression 9.1 Data Simulation Simplified simulation example, so that we know the true parameter \\(\\theta\\). \\(Y\\) : Outcome Cholesterol levels (continuous) \\(A\\) : Exposure Diabetes \\(L\\) : Known Confounders age (continuous) Confounder \\(L\\) (continuous) \\(L\\) ~ N(mean = 10, sd = 1) Treatment \\(A\\) (binary 0/1) Logit \\(P(A = 1)\\) ~ 0.4 L Outcome \\(Y\\) (continuous) Y ~ N(mean = 3 L + \\(\\theta\\) A, sd = 1) True parameter: \\(\\theta = 0.7\\) We want to see, how close the estimates (compared to this \\(\\theta = 0.7\\)) are when we try to estimate this parameter using different methods: regression PS Note that, given the data generating mechanism, \\(L\\) is a confounders, and should be adjusted. require(simcausal) D &lt;- DAG.empty() D &lt;- D + node(&quot;L&quot;, distr = &quot;rnorm&quot;, mean = 10, sd = 1) + node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = plogis(0.4*L)) + node(&quot;Y&quot;, distr = &quot;rnorm&quot;, mean = 3 * L + 0.7 * A, sd = 1) Dset &lt;- set.DAG(D) plotDAG(Dset, xjitter = 0.1, yjitter = .9, edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 1.7), vertex_attrs = list(size = 18, label.cex = 1.8)) ## using the following vertex attributes: ## 181.8NAdarkbluenone0 ## using the following edge attributes: ## 0.50.41.7black1 # Data generating function fnc &lt;- function(n = 10, seedx = 123){ require(simcausal) set.seed(seedx) D &lt;- DAG.empty() D &lt;- D + node(&quot;L&quot;, distr = &quot;rnorm&quot;, mean = 10, sd = 1) + node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = plogis(0.4*L)) + node(&quot;Y&quot;, distr = &quot;rnorm&quot;, mean = 3 * L + 0.7 * A, sd = 1) Dset &lt;- set.DAG(D) A1 &lt;- node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = 1) Dset &lt;- Dset + action(&quot;A1&quot;, nodes = A1) A0 &lt;- node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = 0) Dset &lt;- Dset + action(&quot;A0&quot;, nodes = A0) Cdat &lt;- sim(DAG = Dset, actions = c(&quot;A1&quot;, &quot;A0&quot;), n = n, rndseed = 123) generated.data &lt;- round(cbind(Cdat$A1[c(&quot;ID&quot;, &quot;L&quot;, &quot;Y&quot;)],Cdat$A0[c(&quot;Y&quot;)]),2) names(generated.data) &lt;- c(&quot;ID&quot;, &quot;L&quot;, &quot;Y1&quot;, &quot;Y0&quot;) generated.data &lt;- generated.data[order(generated.data$L, generated.data$ID),] generated.data$A &lt;- sample(c(0,1),n, replace = TRUE) generated.data$Y &lt;- ifelse(generated.data$A==0, generated.data$Y0, generated.data$Y1) counterfactual.dataset&lt;- generated.data[order(generated.data$ID) , ][c(&quot;ID&quot;,&quot;L&quot;,&quot;A&quot;,&quot;Y1&quot;,&quot;Y0&quot;)] observed.dataset&lt;- generated.data[order(generated.data$ID) , ][c(&quot;ID&quot;,&quot;L&quot;,&quot;A&quot;,&quot;Y&quot;)] return(list(counterfactual=counterfactual.dataset, observed=observed.dataset)) } 10 observations from the data generation: result.data &lt;- fnc(n=10) result.data ## $counterfactual ## ID L A Y1 Y0 ## 1 1 9.44 0 30.24 29.54 ## 2 2 9.77 0 30.37 29.67 ## 3 3 11.56 1 35.78 35.08 ## 4 4 10.07 1 31.02 30.32 ## 5 5 10.13 1 30.53 29.83 ## 6 6 11.72 0 37.63 36.93 ## 7 7 10.46 0 32.58 31.88 ## 8 8 8.73 0 24.94 24.24 ## 9 9 9.31 0 29.34 28.64 ## 10 10 9.55 1 28.89 28.19 ## ## $observed ## ID L A Y ## 1 1 9.44 0 29.54 ## 2 2 9.77 0 29.67 ## 3 3 11.56 1 35.78 ## 4 4 10.07 1 31.02 ## 5 5 10.13 1 30.53 ## 6 6 11.72 0 36.93 ## 7 7 10.46 0 31.88 ## 8 8 8.73 0 24.24 ## 9 9 9.31 0 28.64 ## 10 10 9.55 1 28.89 9.2 Treatment effect from counterfactuals True \\(\\theta\\) can be obtained from counterfactual data: result.data$counterfactual$TE &lt;- result.data$counterfactual$Y1- result.data$counterfactual$Y0 result.data$counterfactual ## ID L A Y1 Y0 TE ## 1 1 9.44 0 30.24 29.54 0.7 ## 2 2 9.77 0 30.37 29.67 0.7 ## 3 3 11.56 1 35.78 35.08 0.7 ## 4 4 10.07 1 31.02 30.32 0.7 ## 5 5 10.13 1 30.53 29.83 0.7 ## 6 6 11.72 0 37.63 36.93 0.7 ## 7 7 10.46 0 32.58 31.88 0.7 ## 8 8 8.73 0 24.94 24.24 0.7 ## 9 9 9.31 0 29.34 28.64 0.7 ## 10 10 9.55 1 28.89 28.19 0.7 9.3 Treatment effect from Regression What happens in observed data for a sample of size 10? round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=result.data$observed)),2) ## (Intercept) A ## 30.15 1.41 round(coef(glm(Y ~ A + L, family=&quot;gaussian&quot;, data=result.data$observed)),2) ## (Intercept) A L ## -6.77 -0.17 3.73 What happens in observed data for a sample of size 10000? result.data &lt;- fnc(n=10000) round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=result.data$observed)),2) ## (Intercept) A ## 29.98 0.71 round(coef(glm(Y ~ A + L, family=&quot;gaussian&quot;, data=result.data$observed)),2) ## (Intercept) A L ## -0.06 0.69 3.01 9.4 Treatment effect from PS Propensity score model fitting: require(MatchIt) match.obj &lt;- matchit(A ~ L, method = &quot;nearest&quot;, data = result.data$observed, distance = &#39;logit&#39;, caliper = 0.001, replace = FALSE, ratio = 1) ## Warning: Fewer control units than treated units; not all treated units will get ## a match. match.obj ## A matchit object ## - method: 1:1 nearest neighbor matching without replacement ## - distance: Propensity score [caliper] ## - estimated with logistic regression ## - caliper: &lt;distance&gt; (0) ## - number of obs.: 10000 (original), 8388 (matched) ## - target estimand: ATT ## - covariates: L Results from step 4: crude matched.data &lt;- match.data(match.obj) Results from step 4: adjusted round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=matched.data)),2) ## (Intercept) A ## 30.00 0.69 round(coef(glm(Y ~ A+L, family=&quot;gaussian&quot;, data=matched.data)),2) ## (Intercept) A L ## 0.02 0.69 3.00 9.5 Non-linear Model 9.5.1 Data generation \\(Y\\) : Outcome Cholesterol levels (continuous) \\(A\\) : Exposure Diabetes \\(L\\) : Known Confounders age (continuous) Confounder \\(L\\) (continuous) \\(L\\) ~ N(mean = 10, sd = 1) Treatment \\(A\\) (binary 0/1) Logit \\(P(A = 1)\\) ~ 0.4 L Outcome \\(Y\\) (continuous) Y ~ N(mean = 3 \\(L^3\\) + \\(\\theta\\) A, sd = 1) The only difference is \\(L^3\\) instead of \\(L\\) in the outcome mode. Again, \\(\\theta = 0.7\\) # Data generating function fnc2 &lt;- function(n = 10, seedx = 123){ require(simcausal) set.seed(seedx) D &lt;- DAG.empty() D &lt;- D + node(&quot;L&quot;, distr = &quot;rnorm&quot;, mean = 10, sd = 1) + node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = plogis(0.4*L)) + node(&quot;Y&quot;, distr = &quot;rnorm&quot;, mean = 3 * L^3 + 0.7 * A, sd = 1) Dset &lt;- set.DAG(D) A1 &lt;- node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = 1) Dset &lt;- Dset + action(&quot;A1&quot;, nodes = A1) A0 &lt;- node(&quot;A&quot;, distr = &quot;rbern&quot;, prob = 0) Dset &lt;- Dset + action(&quot;A0&quot;, nodes = A0) Cdat &lt;- sim(DAG = Dset, actions = c(&quot;A1&quot;, &quot;A0&quot;), n = n, rndseed = 123) generated.data &lt;- round(cbind(Cdat$A1[c(&quot;ID&quot;, &quot;L&quot;, &quot;Y&quot;)],Cdat$A0[c(&quot;Y&quot;)]),2) names(generated.data) &lt;- c(&quot;ID&quot;, &quot;L&quot;, &quot;Y1&quot;, &quot;Y0&quot;) generated.data &lt;- generated.data[order(generated.data$L, generated.data$ID),] generated.data$A &lt;- sample(c(0,1),n, replace = TRUE) generated.data$Y &lt;- ifelse(generated.data$A==0, generated.data$Y0, generated.data$Y1) counterfactual.dataset&lt;- generated.data[order(generated.data$ID) , ][c(&quot;ID&quot;,&quot;L&quot;,&quot;A&quot;,&quot;Y1&quot;,&quot;Y0&quot;)] observed.dataset&lt;- generated.data[order(generated.data$ID) , ][c(&quot;ID&quot;,&quot;L&quot;,&quot;A&quot;,&quot;Y&quot;)] return(list(counterfactual=counterfactual.dataset, observed=observed.dataset)) } 9.5.2 Regression result.data &lt;- fnc2(n=10000) Crude estimates round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=result.data$observed)),2) ## (Intercept) A ## 3084.43 7.13 Adjusted estimates fit &lt;- glm(Y ~ A + L, family=&quot;gaussian&quot;, data=result.data$observed) round(coef(fit),2) ## (Intercept) A L ## -6003.99 1.81 909.32 In regression adjustments, the results could be subject to model extrapolation based on linearity assumption. It is sometimes difficult to know whether the adjusted effect is based on extrapolation. Especially true in observational settings. PS may not need such linearity assumption (when non-parametric approaches used for prediction). Dont necessarily mean non-parametric approaches are the best option though! 9.5.3 PS Matching with PS match.obj &lt;- matchit(A ~ L, method = &quot;nearest&quot;, data = result.data$observed, distance = &#39;logit&#39;, replace = FALSE, caliper = 0.001, ratio = 1) match.obj ## A matchit object ## - method: 1:1 nearest neighbor matching without replacement ## - distance: Propensity score [caliper] ## - estimated with logistic regression ## - caliper: &lt;distance&gt; (0) ## - number of obs.: 10000 (original), 8144 (matched) ## - target estimand: ATT ## - covariates: L matched.data &lt;- match.data(match.obj) Results from step 4: crude round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=matched.data)),2) ## (Intercept) A ## 3089.79 0.66 Results from step 4: adjusted round(coef(glm(Y ~ A+L, family=&quot;gaussian&quot;, data=matched.data)),2) ## (Intercept) A L ## -6030.60 0.66 910.73 9.5.4 Machine learning Using gradient boosted method for PS estimation require(twang) result.data$observed$S &lt;- 0 ps.gbm &lt;- ps(A ~ L + S,data = result.data$observed,estimand = &quot;ATT&quot;,n.trees=1000) names(ps.gbm) summary(ps.gbm$ps$es.mean.ATT) result.data$observed$ps &lt;- ps.gbm$ps$es.mean.ATT Matching with PS generated from gradient boosted method require(Matching) match.obj2 &lt;- Match(Y=result.data$observed$Y, Tr=result.data$observed$A, X=result.data$observed$ps, M=1, caliper = 0.001, replace=FALSE) summary(match.obj2) ## ## Estimate... 2.2638 ## SE......... 10.414 ## T-stat..... 0.21739 ## p.val...... 0.82791 ## ## Original number of observations.............. 10000 ## Original number of treated obs............... 4941 ## Matched number of observations............... 4840 ## Matched number of observations (unweighted). 4840 ## ## Caliper (SDs)........................................ 0.001 ## Number of obs dropped by &#39;exact&#39; or &#39;caliper&#39; 101 matched.data2 &lt;- result.data$observed[c(match.obj2$index.treated, match.obj2$index.control),] mb &lt;- MatchBalance(A~L, data=result.data$observed, match.out=match.obj2, nboots=10) Results from step 4: crude round(coef(glm(Y ~ A, family=&quot;gaussian&quot;, data=matched.data2)),2) ## (Intercept) A ## 3075.49 2.26 Results from step 4: adjusted round(coef(glm(Y ~ A+L, family=&quot;gaussian&quot;, data=matched.data2)),2) ## (Intercept) A L ## -6000.63 1.17 908.42 Powerful machine learning method is good at prediction. Propensity score methods rely on obtaining good balance. Always a good idea to check analysis with multiple sensitivity analysis. 9.5.5 Regression is doomed? Not really. Always a god idea to check the diagnostic plots to find any indication of assumption violation: par(mfrow=c(2,2)) plot(fit) Residual plot has a pattern! Indication that we may meed to reset the model-specification. "],["guide.html", "Chapter 10 Reporting Guidelines 10.1 Discipline-specific Reviews 10.2 Suggested Guidelines 10.3 Additional topics", " Chapter 10 Reporting Guidelines While writing journal articles or reports, what are the components we should report? 10.1 Discipline-specific Reviews Propensity score matching most popular Guidelines available for some discipline-specific areas: Cardiovascular (Austin 2007), Infective endocarditis, Intensive care Critical care, anesthesiology, Sepsis, Psychology Cancer (Yao et al. 2017), Multiple sclerosis (Karim et al. 2020) 10.2 Suggested Guidelines Population Be specific about population of interest - ATT vs. ATE - exclusion criteria Intervention Be specific about exposure - no multiple version of treatment - no interference - comparator Covariates How variables are selected - Any important variables not measured? Proxy? - Large list of covariates? See King and Nielsen (2019) PS Model Model selection - interaction or polynomials - logistic vs. machine learning - Residual imbalance and refit PS model PS approach Why PS matching (or other approach) was selected? Sample size Reduction % of the matched data: major issue! Diagnostics Overlap vs. balance assessments - numeric and visual Software Report software, packages 10.3 Additional topics Some of the advanced topics not covered here. Sensitivity analysis - unmeasured confounder / hdPS - any positivity issue? Deleting extremes has consequences! - ad-hoc methods: truncation / trimming: bias-variance trade-off Subgroup analysis Refit within each group for matching - See Ali et al. (2019) for a more complete list Missing data Report clearly about missing data - how missing data handled "],["final.html", "Chapter 11 Final Words 11.1 Common misconception 11.2 Benifits of PS 11.3 Limitations of PS 11.4 Software 11.5 Further Resources", " Chapter 11 Final Words 11.1 Common misconception PS results = causal; regression = non-causal. No. Results from both methods should lead to the same conclusions. (DAgostino Jr 1998) When the results deviate, important to investigate why! Establishing causality requires establishing temporality and intergration of subject area expertise. 11.2 Benifits of PS Intuitive: compare two similar groups 2-step process Encourages researchers to think about the treatment generation process Fit outcome model with only important variables. Allowing to think more about design stage (nice separation from outcome model building process). Fit rich PS model (with higher order terms); focusing on prediction; worry less about overparameterization. Non-parametric (ML) approaches can be used to relax linearity assumption in estimating PS. See more on Lee, Lessler, and Stuart (2010), Pirracchio, Petersen, and Van Der Laan (2015), Alam, Moodie, and Stephens (2019) Reduce dimension, helpful when exposure frequent but outcome rare (event per variable). Smaller outcome model may be helpful in diagnostic checks. Diagnostics Diagnostics (balance checking) much easier compared to residual plot/influence Graphical comparison helps identify areas of non-overlap. 11.3 Limitations of PS Matching population vs. target population: often not the same. PS matching may give effect estimate of a subset, which may be difficult to identify in the actual population! PS can do nothing about unmeasured confounding, neither can outcome regression. 11.4 Software Useful R packages MatchIt cobalt Matching twang Also see Elizabeth Stuarts Propensity Score Software Page for SAS, STATA, SPSS, Excel packages 11.5 Further Resources My workshop page My YouTube channel for related PS materials Teaching by WebApps: particularly this one. "],["references.html", "References", " References Alam, Shomoita, Erica EM Moodie, and David A Stephens. 2019. Should a Propensity Score Model Be Super? The Utility of Ensemble Procedures for Causal Adjustment. Statistics in Medicine 38 (9): 16901702. Ali, M Sanni, Daniel Prieto-Alhambra, Luciane Cruz Lopes, Dandara Ramos, Nivea Bispo, Maria Y Ichihara, Julia M Pescarini, et al. 2019. Propensity Score Methods in Health Technology Assessment: Principles, Extended Applications, and Recent Advances. Frontiers in Pharmacology 10: 973. Austin, Peter C. 2007. Propensity-Score Matching in the Cardiovascular Surgery Literature from 2004 to 2006: A Systematic Review and Suggestions for Improvement. The Journal of Thoracic and Cardiovascular Surgery 134 (5): 112835. . 2009. Balance Diagnostics for Comparing the Distribution of Baseline Covariates Between Treatment Groups in Propensity-Score Matched Samples. Statistics in Medicine 28 (25): 30833107. . 2011a. A Tutorial and Case Study in Propensity Score Analysis: An Application to Estimating the Effect of in-Hospital Smoking Cessation Counseling on Mortality. Multivariate Behavioral Research 46 (1): 11951. . 2011b. An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies. Multivariate Behavioral Research 46 (3): 399424. Austin, Peter C, and Dylan S Small. 2014. The Use of Bootstrapping When Using Propensity-Score Matching Without Replacement: A Simulation Study. Statistics in Medicine 33 (24): 430619. Brookhart, M Alan, Sebastian Schneeweiss, Kenneth J Rothman, Robert J Glynn, Jerry Avorn, and Til Stürmer. 2006. Variable Selection for Propensity Score Models. American Journal of Epidemiology 163 (12): 114956. DAgostino Jr, Ralph B. 1998. Propensity Score Methods for Bias Reduction in the Comparison of a Treatment to a Non-Randomized Control Group. Statistics in Medicine 17 (19): 226581. Gautret, Philippe, Jean-Christophe Lagier, Philippe Parola, Line Meddeb, Morgane Mailhe, Barbara Doudier, Johan Courjon, et al. 2020. Hydroxychloroquine and Azithromycin as a Treatment of COVID-19: Results of an Open-Label Non-Randomized Clinical Trial. International Journal of Antimicrobial Agents 56 (1): 105949. Karim, Mohammad Ehsanul, Menglan Pang, and Robert W Platt. 2018. Can We Train Machine Learning Methods to Outperform the High-Dimensional Propensity Score Algorithm? Epidemiology 29 (2): 19198. Karim, Mohammad Ehsanul, Fabio Pellegrini, Robert W Platt, Gabrielle Simoneau, Julie Rouette, and Carl de Moor. 2020. The Use and Quality of Reporting of Propensity Score Methods in Multiple Sclerosis Literature: A Review. Multiple Sclerosis Journal, 1352458520972557. King, Gary, and Richard Alexander Nielsen. 2019. Why Propensity Scores Should Not Be Used for Matching. Lee, Brian K, Justin Lessler, and Elizabeth A Stuart. 2010. Improving Propensity Score Weighting Using Machine Learning. Statistics in Medicine 29 (3): 33746. Nguyen, Tri-Long, Gary S Collins, Jessica Spence, Jean-Pierre Daurès, PJ Devereaux, Paul Landais, and Yannick Le Manach. 2017. Double-Adjustment in Propensity Score Matching Analysis: Choosing a Threshold for Considering Residual Imbalance. BMC Medical Research Methodology 17 (1): 18. Pirracchio, Romain, Maya L Petersen, and Mark Van Der Laan. 2015. Improving Propensity Score Estimators Robustness to Model Misspecification Using Super Learner. American Journal of Epidemiology 181 (2): 10819. Rosenbaum, Paul R, and Donald B Rubin. 1983. The Central Role of the Propensity Score in Observational Studies for Causal Effects. Biometrika 70 (1): 4155. Stuart, Elizabeth A. 2010. Matching Methods for Causal Inference: A Review and a Look Forward. Statistical Science: A Review Journal of the Institute of Mathematical Statistics 25 (1): 1. Yao, Xiaoxin I, Xiaofei Wang, Paul J Speicher, E Shelley Hwang, Perry Cheng, David H Harpole, Mark F Berry, Deborah Schrag, and Herbert H Pang. 2017. Reporting and Guidelines in Propensity Score Analysis: A Systematic Review of Cancer and Cancer Surgical Studies. JNCI: Journal of the National Cancer Institute 109 (8): djw323. "]]
